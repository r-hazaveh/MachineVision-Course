{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOKHAPO873Fh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create a synthetic full image\n",
        "full_image = np.zeros((400, 400, 3), dtype=np.uint8)\n",
        "cv2.rectangle(full_image, (50, 50), (350, 350), (255, 255, 255), -1)\n",
        "cv2.circle(full_image, (200, 200), 80, (0, 0, 255), -1)\n",
        "cv2.putText(full_image, 'AI', (150, 215), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 0), 3)\n",
        "\n",
        "# Step 2: Create a query image by cropping a part of the full image\n",
        "query_image = full_image[120:280, 120:280]\n",
        "\n",
        "# Step 3: Convert images to grayscale\n",
        "img1 = cv2.cvtColor(query_image, cv2.COLOR_BGR2GRAY)\n",
        "img2 = cv2.cvtColor(full_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Step 4: Use SIFT to detect and compute keypoints and descriptors\n",
        "sift = cv2.SIFT_create()\n",
        "kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "kp2, des2 = sift.detectAndCompute(img2, None)\n",
        "\n",
        "# Step 5: Use FLANN-based matcher\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "search_params = dict(checks=50)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "# Step 6: Apply Lowe's ratio test\n",
        "good = []\n",
        "for m, n in matches:\n",
        "    if m.distance < 0.7 * n.distance:\n",
        "        good.append(m)\n",
        "\n",
        "# Step 7: Match found\n",
        "MIN_MATCH_COUNT = 10\n",
        "result = full_image.copy()\n",
        "\n",
        "if len(good) > MIN_MATCH_COUNT:\n",
        "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "    matchesMask = mask.ravel().tolist()\n",
        "    h, w = img1.shape\n",
        "    pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
        "    dst = cv2.perspectiveTransform(pts, M)\n",
        "    result = cv2.polylines(result, [np.int32(dst)], True, (0, 255, 0), 3, cv2.LINE_AA)\n",
        "else:\n",
        "    print(\"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT))\n",
        "\n",
        "# Step 8: Display the result\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Query Image\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(cv2.cvtColor(full_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Full Image\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Result\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}